{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 .AppleSystemUIFontMonospaced-Regular;}
{\colortbl;\red255\green255\blue255;\red24\green26\blue30;\red24\green26\blue30;}
{\*\expandedcolortbl;;\cssrgb\c12157\c13725\c15686;\cssrgb\c12157\c13725\c15686;}
\margl1440\margr1440\vieww18220\viewh8740\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs27\fsmilli13600 \cf2 \expnd0\expndtw0\kerning0
export BERT_BASE_DIR=/home/abbas/DeepCT3/uncased_L-12_H-768_A-12\
export TRAIN_DATA_FILE=/home/abbas/DeepCT3/data/myalltrain.relevant.docterm_recall\
export OUTPUT_DIR=/home/abbas/DeepCT3/output/marco\
\
\pard\pardeftab720\partightenfactor0

\fs27\fsmilli13600 \cf3 \outl0\strokewidth0 \strokec3 python run_deepct.py \\\
  --task_name=marcodoc \\\
  --do_train=true \\\
  --do_eval=false \\\
  --do_predict=false \\\
  --data_dir=$TRAIN_DATA_FILE \\\
  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\
  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\
  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\
  --max_seq_length=128 \\\
  --train_batch_size=16 \\\
  --learning_rate=2e-5 \\\
  --num_train_epochs=3.0 \\\
  --recall_field=title \\\
  --output_dir=$OUTPUT_DIR\
\pard\pardeftab720\partightenfactor0

\fs27\fsmilli13600 \cf2 \outl0\strokewidth0 \
}